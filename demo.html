<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8">
    <link rel="icon" href="//www.xiph.org/images/logos/xiph.ico" type="image/x-icon" />
    <link rel="stylesheet" title="default demosheet" href="demo.css" type="text/css" />
    <!-- <link rel="stylesheet" title="default demosheet" media="print" href="demo_print.css" type="text/css"/> -->
    <title>Kinoa : Demo</title>
    <script src="ffmap.js"></script>
    <script src="demo.js"></script>
    <script src="noise.js"></script>
    <script src="record.js"></script>
    <!-- <script src="noise.js"></script>
    <script src="noise_interface.js"></script> -->
</head>

<body onload="init_demo();" style="background: black;">
    <div>
        <img style="width: 10%;" src="https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTaACWeJSATVtjHIRTj8X912jTxgVIw1-pWBjIX6C74eQ8w8SyQxQ" alt="Xiph.org and Mozilla" />
        <h1>Kinoa: The ultimate noise supression</h1>
    </div>

    <div>&nbsp;</div>
    <img class="caption" style="width: 100%; padding-top: 1em; margin-left: auto; margin-right: auto;" src="before.jpg" alt="Banner" onmouseover="this.src='after.jpg';" onmouseout="this.src='before.jpg';" />
    <div class="caption">
        The image above shows the spectrogram of the audio before and after (when moving the mouse over) noise suppression.
    </div>

            <h2>Noise Suppression</h2>

            <p>Noise suppression is a pretty old topic in speech processing,
                <a href="http://ieeexplore.ieee.org/document/1163209/">dating back to at least the 70s</a>. As the name implies, the idea is to take a noisy signal and remove as much noise as possible while causing minimum distortion to the speech of
                interest.
            </p>

            <img class="caption" style="width: 500px" src="noise_suppression.png" alt="traditional noise suppression">
            <div class="caption">

                This is a conceptual view of a conventional noise suppression algorithm. A voice activity detection (VAD) module detects when the signal contains voice and when it's just noise. This is used by a noise spectral estimation module to figure out the spectral
                characteristics of the noise (how much power at each frequency). Then, knowing how the noise looks like, it can be "subtracted" (not as simple as it sounds) from the input audio.
            </div>

           

            
            <h2>A Hybrid Approach</h2>

                    <p>We went with a different approach here: keep all the basic signal processing that's needed anyway (not have a neural network attempt to emulate it), but let the neural network learn all the tricky parts that require endless
                        tweaking next to the signal processing. Another thing that's different from <i>some</i> existing work on noise suppression with deep learning is that we're targeting real-time communication rather than speech recognition, so we
                        can't afford to <i>look ahead</i> more than a few milliseconds (in this case 10 ms).
                    </p>

                    <h3>Defining the problem</h3>

                    <p>To avoid having a very large number of outputs &mdash; and thus a large number of neurons &mdash; we decided against working directly with samples or with a spectrum. Instead, we consider frequency
                        <i>bands</i> that follow the Bark scale, a frequency scale that matches how we perceive sounds. We use a total of 22 bands, instead of the 480 (complex) spectral values we would otherwise have to consider.
                    </p>

                    <img class="caption" style="width: 876px;" src="bands.png" alt="frequency bands">
                    <div class="caption">
                        Layout of the Opus bands vs the actual Bark scale. For RNNoise, we use the same base layout as Opus. Since we overlap the bands, the boundaries between the Opus bands become the center of the overlapped RNNoise bands. The bands are wider at higher frequency
                        because the ear has poorer frequency resolution there. At low frequencies, the bands are narrower, but not as narrow as the Bark scale would give because then we would not have enough data to make good estimates.
                    </div>

                    <p>Of course, we cannot reconstruct audio from just the energy in 22 bands. What we can do though, is compute a gain to apply to the signal for each of these bands. You can think about it as using a 22-band equalizer and rapidly changing
                        the level of each band so as to attenuate the noise, but let the signal through.</p>

                    
                    <p>In addition to our cepstral coefficients, we also include:</p>
                    <ul>
                        <li>The first and second derivatives of the first 6 coefficients across frames</li>
                        <li>The pitch period (1/frequency of the fundamental)</li>
                        <li>The pitch gain (voicing strength) in 6 bands</li>
                        <li>A special non-stationarity value that's useful for detecting speech (but beyond the scope of this demo)</li>
                    </ul>

                    <p>That makes a total of 42 input features to the neural network.</p>

                    <h3>Deep architecture</h3>

                    <p>The deep architecture we use is inspired from the traditional approach to noise suppression. Most of the work is done by 3 GRU layers. The figure below shows the layers we use to compute the band gains and how the architecture maps
                        to the traditional steps in noise suppression. Of course, as is often the case with neural networks we have no actual proof that the network is using its layers as we intend, but the fact that the topology works better than others
                        we tried makes it reasonable to think it is behaving as we designed it.
                    </p>

                    <img class="caption" style="width: 500px" src="topology.png" alt="network topology">
                    <div class="caption">
                        Topology of the neural network used in this project. Each box represents a layer of neurons, with the number of units indicated in parentheses. <i>Dense</i> layers are fully-connected, non-recurrent layers. One of the outputs of
                        the network is a set of gains to apply at different frequencies. The other output is a voice activity probability, which is not used for noise suppression but is a useful by-product of the network.
                    </div>

                    <h2>Show Me the Samples!</h2>

                    
                    <p>The algorithm runs in real-time but we've purposely <b>delayed it by a few seconds</b> to make it easier to hear the denoised output.
                        <b>Make sure to wear headphones otherwise you'll hear a feedback loop.</b> To start the demo, select either "No suppression" or "RNNoise". You can toggle between the two to see the effect of the suppression. If your input doesn't
                        have enough noise, you can artificially add some by clicking the "white noise" button. </p>

                    <div class="comparison">
                        <div>
                            <p class="compare_label" style="display: inline-block">Suppression algorithm</p>
                            <ul class="algorithm">
                                <li onclick="liveNoiseSuppression(0, this);" id="default_live_noise_suppression">Off</li>
                                <li onclick="liveNoiseSuppression(1, this);">No suppression</li>
                                <li onclick="liveNoiseSuppression(2, this);">With Kinoa</li>
                            </ul>
                        </div>

                        <p class="compare_label" style="display: inline-block">Noise type</p>
                        <ul class="bitrate">
                            <li onclick="liveNoise(0, this);" id="default_live_noise">None</li>
                            <li onclick="liveNoise(1, this);">Stream noise</li>
                        </ul>
                    </div>

                    <canvas id="source_spectrogram" width="16" height="16"></canvas>
                    <canvas id="destination_spectrogram" width="16" height="16"></canvas>

                    

</body>

</html>